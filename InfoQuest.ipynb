{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b44cda-5d06-4f37-82c6-60985d8ffb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e591c01-ff26-435d-adcf-5fdeea349535",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = pd.read_json(\"D:/Pythonn/train-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd49fa6-e795-4885-9cff-62f8fde61111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version                                               data\n",
       "0    v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
       "1    v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2    v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3    v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
       "4    v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd54f71-778f-481c-bea4-ada03202dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del squad['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130606ef-3642-4298-a1be-68e9f2f82cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['text','question','answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c87c14-2ec7-4419-93b6-910798ad6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6f59c0-3833-433b-b3e5-1e65d36e0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index , row in squad.iterrows():\n",
    "    for i in range(len(row['data']['paragraphs'])):\n",
    "        for j in (row['data']['paragraphs'][i]['qas']):\n",
    "            temp = []\n",
    "            temp.append((row['data']['paragraphs'][i]['context']))\n",
    "            temp.append(j['question'])\n",
    "            if j[\"answers\"]:\n",
    "               temp.append(j[\"answers\"][0][\"text\"])\n",
    "            else:\n",
    "               temp.append(\"\")\n",
    "        comp_list.append(temp)\n",
    "\n",
    "new_df = pd.DataFrame(comp_list, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121739ce-d071-415a-bb76-4676b692aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"squad.csv\", index = False)\n",
    "\n",
    "data = pd.read_csv(\"squad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e314a1f3-933b-4623-a84d-9985fde846a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>What was the name of Beyoncé's first solo album?</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Following the disbandment of Destiny's Child i...</td>\n",
       "      <td>What is the name of Beyoncé's alter-ego?</td>\n",
       "      <td>Sasha Fierce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A self-described \"modern-day feminist\", Beyonc...</td>\n",
       "      <td>What magazine named Beyoncé as the most powerf...</td>\n",
       "      <td>Forbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyoncé Giselle Knowles was born in Houston, T...</td>\n",
       "      <td>Beyoncé was raised in what religion?</td>\n",
       "      <td>Methodist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyoncé attended St. Mary's Elementary School ...</td>\n",
       "      <td>What choir did Beyoncé sing in for two years?</td>\n",
       "      <td>St. John's United Methodist Church</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
       "1  Following the disbandment of Destiny's Child i...   \n",
       "2  A self-described \"modern-day feminist\", Beyonc...   \n",
       "3  Beyoncé Giselle Knowles was born in Houston, T...   \n",
       "4  Beyoncé attended St. Mary's Elementary School ...   \n",
       "\n",
       "                                            question  \\\n",
       "0   What was the name of Beyoncé's first solo album?   \n",
       "1           What is the name of Beyoncé's alter-ego?   \n",
       "2  What magazine named Beyoncé as the most powerf...   \n",
       "3               Beyoncé was raised in what religion?   \n",
       "4      What choir did Beyoncé sing in for two years?   \n",
       "\n",
       "                               answer  \n",
       "0                 Dangerously in Love  \n",
       "1                        Sasha Fierce  \n",
       "2                              Forbes  \n",
       "3                           Methodist  \n",
       "4  St. John's United Methodist Church  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72575309-e1fb-4fc1-8243-af3faa31e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548fcce2-8ffd-4d98-aec3-cdbea5813fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087ec7d3-b19d-4bb4-a91f-3930aec76cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "\n",
    "question = data['question'][random_num]\n",
    "text = data['text'][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f58859-a445-4e07-a66c-f82df1d8e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(question, text)\n",
    "print(format(len(inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "336adce3-d6b3-499a-8205-1c62ae9986ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "what       2,054\n",
      "is         2,003\n",
      "the        1,996\n",
      "name       2,171\n",
      "of         1,997\n",
      "the        1,996\n",
      "special    2,569\n",
      "residence   5,039\n",
      "built      2,328\n",
      "for        2,005\n",
      "the        1,996\n",
      "citizens   4,480\n",
      "of         1,997\n",
      "france     2,605\n",
      "in         1,999\n",
      "paris      3,000\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "the        1,996\n",
      "palais    22,113\n",
      "des        4,078\n",
      "pa         6,643\n",
      "##pes     10,374\n",
      "in         1,999\n",
      "av        20,704\n",
      "##ignon   24,796\n",
      "is         2,003\n",
      "the        1,996\n",
      "best       2,190\n",
      "complete   3,143\n",
      "large      2,312\n",
      "royal      2,548\n",
      "palace     4,186\n",
      ",          1,010\n",
      "alongside   4,077\n",
      "the        1,996\n",
      "royal      2,548\n",
      "palace     4,186\n",
      "of         1,997\n",
      "ol        19,330\n",
      "##ite      4,221\n",
      ",          1,010\n",
      "built      2,328\n",
      "during     2,076\n",
      "the        1,996\n",
      "13th       6,122\n",
      "and        1,998\n",
      "14th       6,400\n",
      "centuries   4,693\n",
      "for        2,005\n",
      "the        1,996\n",
      "kings      5,465\n",
      "of         1,997\n",
      "navarre   21,260\n",
      ".          1,012\n",
      "the        1,996\n",
      "mal       15,451\n",
      "##bor     12,821\n",
      "##k        2,243\n",
      "castle     3,317\n",
      "built      2,328\n",
      "for        2,005\n",
      "the        1,996\n",
      "master     3,040\n",
      "of         1,997\n",
      "the        1,996\n",
      "te         8,915\n",
      "##uto     16,161\n",
      "##nic      8,713\n",
      "order      2,344\n",
      "is         2,003\n",
      "an         2,019\n",
      "example    2,742\n",
      "of         1,997\n",
      "brick      5,318\n",
      "gothic     7,788\n",
      "architecture   4,294\n",
      ".          1,012\n",
      "partial    7,704\n",
      "survival   7,691\n",
      "##s        2,015\n",
      "of         1,997\n",
      "former     2,280\n",
      "royal      2,548\n",
      "residences  14,094\n",
      "include    2,421\n",
      "the        1,996\n",
      "dog        3,899\n",
      "##e        2,063\n",
      "'          1,005\n",
      "s          1,055\n",
      "palace     4,186\n",
      "of         1,997\n",
      "venice     7,914\n",
      ",          1,010\n",
      "the        1,996\n",
      "pal       14,412\n",
      "##au       4,887\n",
      "de         2,139\n",
      "la         2,474\n",
      "general    2,236\n",
      "##ita      6,590\n",
      "##t        2,102\n",
      "in         1,999\n",
      "barcelona   7,623\n",
      ",          1,010\n",
      "built      2,328\n",
      "in         1,999\n",
      "the        1,996\n",
      "15th       6,286\n",
      "century    2,301\n",
      "for        2,005\n",
      "the        1,996\n",
      "kings      5,465\n",
      "of         1,997\n",
      "aragon    16,146\n",
      ",          1,010\n",
      "or         2,030\n",
      "the        1,996\n",
      "famous     3,297\n",
      "con        9,530\n",
      "##cier    19,562\n",
      "##ger      4,590\n",
      "##ie       2,666\n",
      ",          1,010\n",
      "former     2,280\n",
      "palace     4,186\n",
      "of         1,997\n",
      "the        1,996\n",
      "kings      5,465\n",
      "of         1,997\n",
      "france     2,605\n",
      ",          1,010\n",
      "in         1,999\n",
      "paris      3,000\n",
      ".          1,012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs)\n",
    " \n",
    "for token, id in zip(tokens, inputs):\n",
    "   print('{:8}{:8,}'.format(token, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b379db1a-0497-42a1-8b66-4d95daa198d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99dd60de-c5e8-4fe4-9c87-caf4e1002f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce5967f-6622-4f60-be99-54b9c3d19989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "19\n",
      "119\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = inputs.index(tokenizer.sep_token_id)\n",
    "print(sep_idx)\n",
    " \n",
    "#number of tokens in segment A - question\n",
    "num_seg_a = sep_idx+1\n",
    "print(num_seg_a)\n",
    " \n",
    "#number of tokens in segment B - text\n",
    "num_seg_b = len(inputs) - num_seg_a\n",
    "print(num_seg_b)\n",
    " \n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "print(segment_ids)\n",
    " \n",
    "assert len(segment_ids) == len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "898301ff-6b56-402d-88b5-e9ef2858811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "439acbc3-577e-49c7-a86a-25fd7fb5a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(torch.tensor([inputs]), token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ac50d82-d283-4425-a1f8-bbda632f89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "The palais des papes in avignon is the best complete large royal palace, alongside the royal palace of olite, built during the 13th and 14th centuries for the kings of navarre. the malbork castle built for the master of the teutonic order is an example of brick gothic architecture. partial survivals of former royal residences include the doge's palace of venice, the palau de la generalitat in barcelona, built in the 15th century for the kings of aragon, or the famous conciergerie, former palace of the kings of france, in paris.\n",
      "\n",
      "Question:\n",
      "What is the name of the special residence built for the citizens of france in paris?\n",
      "\n",
      "Answer:\n",
      "Con ##cier ##ger ##ie.\n"
     ]
    }
   ],
   "source": [
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "#print(answer_start, answer_end)\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "   answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "   print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "  \n",
    "print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7814cd77-0daf-4c65-93a8-4f984b0bb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nswer = tokens[answer_start]\n",
    " \n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "   if tokens[i][0:2] == \"##\":\n",
    "       answer += tokens[i][2:]\n",
    "   else:\n",
    "       answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae0b88e5-1ca8-46bd-8d65-d63519364796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "  \n",
    "   #tokenize question and text in ids as a pair\n",
    "   input_ids = tokenizer.encode(question, text)\n",
    "  \n",
    "   #string version of tokenized ids\n",
    "   tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "   #segment IDs\n",
    "   #first occurence of [SEP] token\n",
    "   sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    " \n",
    "   #number of tokens in segment A - question\n",
    "   num_seg_a = sep_idx+1\n",
    " \n",
    "   #number of tokens in segment B - text\n",
    "   num_seg_b = len(input_ids) - num_seg_a\n",
    "  \n",
    "   #list of 0s and 1s\n",
    "   segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "  \n",
    "   assert len(segment_ids) == len(input_ids)\n",
    "  \n",
    "   #model output using input_ids and segment_ids\n",
    "   output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "  \n",
    "   #reconstructing the answer\n",
    "   answer_start = torch.argmax(output.start_logits)\n",
    "   answer_end = torch.argmax(output.end_logits)\n",
    " \n",
    "   if answer_end >= answer_start:\n",
    "       answer = tokens[answer_start]\n",
    "       for i in range(answer_start+1, answer_end+1):\n",
    "           if tokens[i][0:2] == \"##\":\n",
    "               answer = \"\"\n",
    "           else:\n",
    "               answer += \" \" + tokens[i]\n",
    "              \n",
    "   if answer.startswith(\"[CLS]\"):\n",
    "       answer = \"Unable to find the answer to your question.\"\n",
    "  \n",
    "#     print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "#     print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "   print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7826f7-7554-4dbb-b2d6-c9681fef6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = input(\"Please enter your text: \\n\")\n",
    "# question = input(\"\\nPlease enter your question: \\n\")\n",
    " \n",
    "# while True:\n",
    "#    question_answer(question, text)\n",
    "  \n",
    "#    flag = True\n",
    "#    flag_N = False\n",
    "  \n",
    "#    while flag:\n",
    "#        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "#        if response[0] == \"y\":\n",
    "#            question = input(\"\\nPlease enter your question: \\n\")\n",
    "#            flag = False\n",
    "#        elif response[0] == \"n\":\n",
    "#            print(\"\\nBye!\")\n",
    "#            flag = False\n",
    "#            flag_N = True\n",
    "          \n",
    "#    if flag_N == True:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fd05d2-2574-4a86-8ddc-6621194a54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba35d5b5-f532-4cd6-a2be-ce326de8e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d2b975-edc5-4b39-9275-be99213a46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia('Tomdara','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7efb702-e4cd-44eb-b3ce-1fd5cb4a59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikipedia_data(question , top_n=1):\n",
    "    search_results = wikipedia.search(question)\n",
    "\n",
    "    articles = []\n",
    "    for title in search_results[:top_n]:\n",
    "        page = wiki_wiki.page(title)\n",
    "        if page.exists():\n",
    "            articles.append(page.text)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4926d34-48d9-4472-b3cd-00a8181a02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question: \n",
      " What is Black Hole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " where gravity is so strong that nothing , including light and other electromagnetic waves , is capable of possessing enough energy to escape it\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    "articles = fetch_wikipedia_data(question)\n",
    "article = articles[0]\n",
    "text = article[0:1000]\n",
    "answer = question_answer(question, text)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505bede-4d47-4e3e-a622-74b4ada27fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
